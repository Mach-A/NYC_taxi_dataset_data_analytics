{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "ByFJc08QYIz9",
        "outputId": "3752882c-3105-4cb3-ce50-86fd4f989322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fdf91713110>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://73f7ad714660:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>NYC Yellow Taxi ML problems</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# install and set up Spark -- PySpark\n",
        "\n",
        "# SYSTEM SETUP\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# ✅ Correct download link for Spark 3.4.1 (tested)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# ✅ Extract Spark package\n",
        "!tar -xzf spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Install Spark Python bindings\n",
        "!pip install -q findspark\n",
        "!pip install -q pyspark py4j\n",
        "\n",
        "import os\n",
        "import findspark\n",
        "\n",
        "# ✅ Set environment paths\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--driver-memory 12g pyspark-shell\"\n",
        "\n",
        "# ✅ Initialize Spark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"NYC Yellow Taxi ML problems\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "r8tGCBuUYecT",
        "outputId": "5a3912cf-d70b-47c5-cfe5-dacd876ac07b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fdf91713110>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://73f7ad714660:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>NYC Yellow Taxi ML problems</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access the same taxi_zones dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "GoeB-_E2Yyne",
        "outputId": "bfb10c96-5583-4e90-94df-f93516ca33aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ee834c1-241f-4932-90ab-08114adbcd4a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ee834c1-241f-4932-90ab-08114adbcd4a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving taxi_zone_lookup.csv to taxi_zone_lookup (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then the Yellow Taxi data for 6 months Jan-June 2024\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "3SQoU_fUY2iQ",
        "outputId": "c7ad52c7-f580-4607-928c-1c440dcc47ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-18278b7e-e559-4c11-be40-8806616fe35b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-18278b7e-e559-4c11-be40-8806616fe35b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving yellow_tripdata_2024-01.parquet to yellow_tripdata_2024-01 (2).parquet\n",
            "Saving yellow_tripdata_2024-02.parquet to yellow_tripdata_2024-02 (2).parquet\n",
            "Saving yellow_tripdata_2024-03.parquet to yellow_tripdata_2024-03 (2).parquet\n",
            "Saving yellow_tripdata_2024-04.parquet to yellow_tripdata_2024-04 (2).parquet\n",
            "Saving yellow_tripdata_2024-05.parquet to yellow_tripdata_2024-05 (2).parquet\n",
            "Saving yellow_tripdata_2024-06.parquet to yellow_tripdata_2024-06 (2).parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"NYC Yellow Taxi ML problems\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "# Read CSV (taxi lookup)\n",
        "taxi_zones = spark.read.csv('/content/taxi_zone_lookup.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Read Parquet (yellow trip data)\n",
        "tripdata1 = spark.read.parquet('/content/yellow_tripdata_2024-01.parquet', header=True, inferSchema=True)\n",
        "tripdata2 = spark.read.parquet('/content/yellow_tripdata_2024-02.parquet', header=True, inferSchema=True)\n",
        "tripdata3 = spark.read.parquet('/content/yellow_tripdata_2024-03.parquet', header=True, inferSchema=True)\n",
        "tripdata4 = spark.read.parquet('/content/yellow_tripdata_2024-04.parquet', header=True, inferSchema=True)\n",
        "tripdata5 = spark.read.parquet('/content/yellow_tripdata_2024-05.parquet', header=True, inferSchema=True)\n",
        "tripdata6 = spark.read.parquet('/content/yellow_tripdata_2024-06.parquet', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "LhAD4P4-Y-cw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge the 6 monthly tripdata files uploaded into one file\n",
        "\n",
        "tripdata = tripdata1.union(tripdata2).union(tripdata3).union(tripdata4).union(tripdata5).union(tripdata6)\n",
        "tripdata.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zukjNmuuZJJc",
        "outputId": "ea64b057-c661-4d87-95ac-2b3eab48e7d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20332093"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace null entries with their column average\n",
        "\n",
        "tripdatav1 = tripdata.drop(\"RatecodeID\", \"store_and_fwd_flag\")\n",
        "\n",
        "from pyspark.sql.functions import avg\n",
        "averages = tripdatav1.select(\n",
        "    avg(\"passenger_count\").alias(\"pass_count_avg\"),\n",
        "    avg(\"congestion_surcharge\").alias(\"conges_sur_avg\"),\n",
        "    avg(\"airport_fee\").alias(\"airp_fee_avg\")\n",
        ").collect()[0]\n",
        "\n",
        "avg_passenger = averages[\"pass_count_avg\"]\n",
        "avg_congestion = averages[\"conges_sur_avg\"]\n",
        "avg_airport = averages[\"airp_fee_avg\"]\n",
        "\n",
        "# then fill the null values now that we have each column average\n",
        "tripdatav2 = tripdatav1.fillna({\n",
        "    \"passenger_count\": avg_passenger,\n",
        "    \"congestion_surcharge\": avg_congestion,\n",
        "    \"airport_fee\": avg_airport})"
      ],
      "metadata": {
        "id": "TBCITkLPZY6B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# match and update the dataset with the taxi_zone dataset\n",
        "\n",
        "# identify each matching columns across both taxi_zone and yellow_taxi dataset above\n",
        "PULocationID = tripdatav2['PULocationID']\n",
        "DOLocationID = tripdatav2['DOLocationID']\n",
        "LocationID = taxi_zones['LocationID']\n",
        "Borough = taxi_zones['Borough']\n",
        "Zone = taxi_zones['Zone']\n",
        "service_zone = taxi_zones['service_zone']"
      ],
      "metadata": {
        "id": "rEYIQy2qZltk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# match taxi zone columns to PU(pickup) column and rename the new taxi_zones columns\n",
        "tripdatav2_1 = tripdatav2.join(taxi_zones, tripdatav2['PULocationID']== taxi_zones['LocationID'], how='left').withColumnRenamed('Borough', 'PUBorough').withColumnRenamed('Zone', 'PUZone').withColumnRenamed('service_zone', 'PUService_zone')\n",
        "# take out Location ID from taxi_zones after matching, as is no more needed\n",
        "tripdatav2_1 = tripdatav2_1.drop('LocationID')"
      ],
      "metadata": {
        "id": "pf-Q6-pFZxNA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# match taxi zone columns to DO(dropoff) column with the updated DF above and also rename the new taxi_zones columns\n",
        "tripdatav2_2 = tripdatav2_1.join(taxi_zones, tripdatav2['DOLocationID']== taxi_zones['LocationID'], how='left').withColumnRenamed('Borough', 'DOBorough').withColumnRenamed('Zone', 'DOZone').withColumnRenamed('service_zone', 'DOService_zone')\n",
        "# also take out Location ID from taxi_zones after matching, as is no more needed\n",
        "tripdatav2_2 = tripdatav2_2.drop('LocationID')"
      ],
      "metadata": {
        "id": "N-oQYAHTZzWl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ....rearrange the columns closer to the PU & DO codes\n",
        "columns = tripdatav2_2.columns\n",
        "\n",
        "col_num = [0, 1, 2, 3, 4, 5, 17, 18, 19, 6, 20, 21, 22, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
        "rearr_columns = [columns[i] for i in col_num]\n",
        "\n",
        "tripdatav4 = tripdatav2_2.select(rearr_columns)"
      ],
      "metadata": {
        "id": "-FCvNYCOZ3BI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "TASK 3\n",
        "\n",
        "ML Problem 1 - to predict the daily taxes across Jan_June 2025\n",
        "--------------------------------------------------------------\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cEYx7oiza1B_",
        "outputId": "834af5ce-15c3-4c00-8b20-c301a88bef7d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTASK 3\\n\\nML Problem 1 - to predict the daily taxes across Jan_June 2025\\n--------------------------------------------------------------\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import month, year, to_date\n",
        "from pyspark.sql.functions import sum as Fsum, concat_ws\n",
        "from pyspark.sql.functions import rank\n",
        "from pyspark.sql.types import DecimalType\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number, col\n",
        "\n",
        "# focus on rides within Jan-June of 2024\n",
        "months_tripdata = tripdatav4.filter(\n",
        "    (year(\"tpep_pickup_datetime\") == 2024) & (month(\"tpep_pickup_datetime\").isin(1, 2, 3, 4, 5, 6)))\n",
        "\n",
        "# aiming to predict total monthly taxes\n",
        "months_tripdata1 = months_tripdata.withColumn(\"pickup_date\", to_date(\"tpep_pickup_datetime\")) \\\n",
        "       .withColumn(\"month\", month(\"pickup_date\")) \\\n",
        "       .withColumn(\"year\", year(\"pickup_date\"))\n",
        "\n",
        "tax_tripdata1 = months_tripdata1.groupBy(\"year\", \"month\", \"pickup_date\").agg(\n",
        "    Fsum(\"mta_tax\").alias(\"total_mta_tax\"),\n",
        "    Fsum(\"congestion_surcharge\").alias(\"total_congestn\"),\n",
        "    Fsum(\"improvement_surcharge\").alias(\"total_improvmnt\"),\n",
        "    Fsum(\"airport_fee\").alias(\"total_airp\"))\n",
        "\n",
        "tax_tripdata1 = tax_tripdata1.withColumn(\"tol_tax\",\n",
        "                                   col(\"total_mta_tax\") + col(\"total_congestn\") +\n",
        "                                   col(\"total_improvmnt\") + col(\"total_airp\"))"
      ],
      "metadata": {
        "id": "bZp2kmqLaKsC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# and then tax model features\n",
        "tax_features = [\"total_mta_tax\", \"total_congestn\", \"total_improvmnt\", \"total_airp\"]\n",
        "# using VectorAssemble\n",
        "tax_assembler = VectorAssembler(inputCols=tax_features, outputCol=\"t_features\")\n",
        "tax_updated = tax_assembler.transform(tax_tripdata1).select(\"t_features\", \"tol_tax\")\n",
        "\n",
        "# the usual data split; 80:20(train:test)\n",
        "tax_train_data, tax_test_data = tax_updated.randomSplit([0.8, 0.2], seed=0)\n",
        "# the tax model\n",
        "lr = LinearRegression(featuresCol=\"t_features\", labelCol=\"tol_tax\")\n",
        "tax_model = lr.fit(tax_train_data)\n",
        "\n",
        "# model evaluation and prediction and give it a unique identifer for other predictions\n",
        "lr = lr.setPredictionCol(\"reg_prediction\")\n",
        "# for tuning of hyperparameters\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(lr.regParam, [0.01, 0.1, 0.5])\n",
        "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "             .addGrid(lr.maxIter, [50, 100])\n",
        "             .build())\n",
        "\n",
        "reg_evaluator = RegressionEvaluator(labelCol=\"tol_tax\", predictionCol=\"reg_prediction\", metricName=\"rmse\")\n",
        "\n",
        "# set up CrossValidation for 4 folds\n",
        "tax_cross = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=reg_evaluator, numFolds=4, seed=0)\n",
        "tax_cross_model = tax_cross.fit(tax_train_data)\n",
        "\n",
        "tax_ok_model = tax_cross_model.bestModel\n",
        "tax_predictions = tax_ok_model.transform(tax_test_data)\n",
        "\n",
        "tax_test_rmse = reg_evaluator.evaluate(tax_predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE) = {tax_test_rmse:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKs81kIMam8J",
        "outputId": "6d1ee8e5-e09e-4391-d58e-99ab89b91d5a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) = 0.167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ML Problem 2 - to predict if a driver will be tip or not\n",
        "--------------------------------------------------------\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6B9v-9d0a4HY",
        "outputId": "25026043-ae76-46b7-e06c-0ad5ff35f8d7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nML Problem 2 - to predict if a driver will be tip or not\\n--------------------------------------------------------\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# create an additional column if tip is given = 1 else 0\n",
        "tip_tripdata = months_tripdata.withColumn(\"tip_given\", when(col(\"tip_amount\") > 0, 1).otherwise(0))\n",
        "\n",
        "tip_features = [\"fare_amount\", \"trip_distance\", \"passenger_count\", \"total_amount\"]\n",
        "\n",
        "tip_assembler = VectorAssembler(inputCols=tip_features, outputCol=\"ti_features\")\n",
        "tip_updated= tip_assembler.transform(tip_tripdata).select(\"ti_features\", \"tip_given\")\n",
        "\n",
        "# the usual data split; 80:20(train:test)\n",
        "tip_train_data, tip_test_data = tip_updated.randomSplit([0.8, 0.2], seed=0)\n",
        "tip_lr = LogisticRegression(featuresCol=\"ti_features\", labelCol=\"tip_given\")\n",
        "tip_lr = tip_lr.setPredictionCol(\"acc_prediction\")\n",
        "\n",
        "\n",
        "# model evaluation metrics using \"Accuracy\"\n",
        "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"tip_given\", predictionCol=\"acc_prediction\", metricName=\"accuracy\")\n",
        "\n",
        "tip_model = tip_lr.fit(tip_train_data)\n",
        "tip_predictions = tip_model.transform(tip_test_data)\n",
        "\n",
        "tip_accuracy = acc_evaluator.evaluate(tip_predictions)\n",
        "print(f\"Tip Accuracy = {tip_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB9MFQzja7lR",
        "outputId": "2f3dec5b-c8fc-4b4f-aa70-d9d8bf8769e4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tip Accuracy = 0.913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paramGrid1 = (ParamGridBuilder()\n",
        "             .addGrid(tip_lr.regParam, [0.01, 0.1, 0.5])\n",
        "             .addGrid(tip_lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "             .build())\n",
        "crossval = CrossValidator(\n",
        "    estimator=tip_lr,\n",
        "    estimatorParamMaps=paramGrid1,\n",
        "    evaluator=acc_evaluator,\n",
        "    numFolds=3,\n",
        "    parallelism=2)\n",
        "\n",
        "cv_lr_model = crossval.fit(tip_train_data)\n",
        "tip_cv_predictions = cv_lr_model.transform(tip_test_data)\n",
        "tip_cv_accuracy = acc_evaluator.evaluate(tip_cv_predictions)\n",
        "print(f\"Tip Accuracy after Hyperparameter Tuning = {tip_cv_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppLkM61rp1Nz",
        "outputId": "ee349b71-e579-472f-d3f1-1eadf1b6e432"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tip Accuracy after Hyperparameter Tuning = 0.813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to further show tip and no tip breakdown\n",
        "tip_tripdata.groupBy(\"tip_given\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsHoiA1tbBSq",
        "outputId": "ac5764b5-8f95-4f05-c402-e3774ef0a7a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+\n",
            "|tip_given|   count|\n",
            "+---------+--------+\n",
            "|        1|14622457|\n",
            "|        0| 5709597|\n",
            "+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ML Problem 3 - to predict the trip payment type\n",
        "-----------------------------------------------\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "oAn6TUFRbJT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we check all the payment types code(integers) available\n",
        "\n",
        "# how many zones does each Borough have\n",
        "tip_tripdata.groupBy(\"payment_type\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gau_WFtbL_A",
        "outputId": "c17da13a-54e0-4384-f4b6-02e85319534f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------+\n",
            "|payment_type|   count|\n",
            "+------------+--------+\n",
            "|           1|15111906|\n",
            "|           2| 2773053|\n",
            "|           0| 1975985|\n",
            "|           4|  337758|\n",
            "|           3|  133350|\n",
            "|           5|       2|\n",
            "+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we proceed to use FeedForward Neural Network to predict the payment type\n",
        "\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "payment_features = [\"trip_distance\", \"passenger_count\", \"tip_amount\", \"total_amount\"]\n",
        "\n",
        "payment_assembler = VectorAssembler(inputCols=payment_features, outputCol=\"pay_features\")\n",
        "payment_updated = payment_assembler.transform(tip_tripdata)\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"payment_type\", outputCol=\"payment_label\")\n",
        "payment_updated = indexer.fit(payment_updated).transform(payment_updated)\n",
        "\n",
        "# the usual data split; 80:20(train:test)\n",
        "pay_train_data, pay_test_data = payment_updated.randomSplit([0.8, 0.2], seed=0)\n",
        "\n",
        "# model architecture\n",
        "pay_layers = [4, 32, 16, 6]  # --> features, hidden1, hidden2, payment types\n",
        "mlp = MultilayerPerceptronClassifier(featuresCol=\"pay_features\", labelCol=\"payment_label\", predictionCol=\"pay_prediction\",\n",
        "                                     maxIter=50, layers=pay_layers, blockSize=128, seed=42)\n",
        "\n",
        "\n",
        "payf1_evaluator = MulticlassClassificationEvaluator(labelCol=\"payment_label\", predictionCol=\"pay_prediction\", metricName=\"f1\")\n",
        "\n",
        "\n",
        "pay_model = mlp.fit(pay_train_data)\n",
        "pay_f1predictions = pay_model.transform(pay_test_data)\n",
        "\n",
        "pay_f1accuracy = payf1_evaluator.evaluate(pay_f1predictions)\n",
        "print(f\"The Payment Type Option F1 score = {pay_f1accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv-I694EZXyS",
        "outputId": "c26436d3-5b2b-416f-bb20-d13c06ea951f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Payment Type Option F1 score = 0.816\n"
          ]
        }
      ]
    }
  ]
}